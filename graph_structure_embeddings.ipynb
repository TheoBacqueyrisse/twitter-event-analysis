{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1502/3166726442.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: node2vec in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.4.6)\n",
      "Requirement already satisfied: gensim<5.0.0,>=4.1.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from node2vec) (4.3.2)\n",
      "Requirement already satisfied: joblib<2.0.0,>=1.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from node2vec) (1.3.2)\n",
      "Requirement already satisfied: networkx<3.0,>=2.5 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from node2vec) (2.8.8)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.19.5 in /home/codespace/.local/lib/python3.10/site-packages (from node2vec) (1.26.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.55.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from node2vec) (4.66.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /home/codespace/.local/lib/python3.10/site-packages (from gensim<5.0.0,>=4.1.2->node2vec) (1.12.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from gensim<5.0.0,>=4.1.2->node2vec) (7.0.3)\n",
      "Requirement already satisfied: wrapt in /usr/local/python/3.10.13/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim<5.0.0,>=4.1.2->node2vec) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "%pip install node2vec\n",
    "from node2vec import Node2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_event = 'wildfire'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'subgraphs_data/{chosen_event}_subgraph.graphml'\n",
    "g = nx.read_graphml(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us first get access to the users of the chosen event\n",
    "users = []\n",
    "for node, data in g.nodes(data=True):\n",
    "    for key, value in data.items():\n",
    "        if key == 'labels':\n",
    "            if value == ':User':\n",
    "                users.append({node : data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select first a sample of 100 users\n",
    "random.seed(55)\n",
    "users_sample = random.sample(users, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the nodes ids in order to get a subgraph containing our sample of nodes\n",
    "node_sample_ids = []\n",
    "for i in range(len(users_sample)):\n",
    "    for key, _ in users_sample[i].items():\n",
    "        node_sample_ids.append(key)\n",
    "\n",
    "# define the subgraph with the sample of 100 nodes\n",
    "sample_graph = g.subgraph(node_sample_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 100/100 [00:00<00:00, 43947.02it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:00<00:00, 2212.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# define a Node2Vec model, and extract the walks from this model\n",
    "node2vec = Node2Vec(sample_graph)\n",
    "walks = node2vec.walks\n",
    "\n",
    "# now, apply a Word2Vec model to the walks that we obtained, and set the vector size to 25 to obtain embeddings of size 25\n",
    "modelw2v = Word2Vec(walks, vector_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the embeddings our sample of 100 nodes\n",
    "node_embeddings = {node: modelw2v.wv[node] for node in sample_graph.nodes()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_embeddings = []\n",
    "for key, value in node_embeddings.items():\n",
    "    list_of_embeddings.append({key : value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = [[0 for _ in range(100)] for _ in range(100)]\n",
    "\n",
    "for i, emb_i_dict in enumerate(list_of_embeddings):\n",
    "    for j, emb_j_dict in enumerate(list_of_embeddings):\n",
    "        emb_i = next(iter(emb_i_dict.values())) \n",
    "        emb_j = next(iter(emb_j_dict.values()))\n",
    "\n",
    "        cosine_sim = cosine_similarity([emb_i], [emb_j])[0][0]\n",
    "        cos_sim[i][j] = cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_cos_sim = np.array(cos_sim)\n",
    "np.fill_diagonal(arr_cos_sim, -np.inf)\n",
    "\n",
    "# 10 most similar nodes\n",
    "v = []\n",
    "\n",
    "for _ in range(10):\n",
    "    max_index = np.argmax(arr_cos_sim)\n",
    "    max_row_index, max_col_index = np.unravel_index(max_index, np.array(arr_cos_sim).shape)\n",
    "    arr_cos_sim[max_row_index][max_col_index] = -np.inf\n",
    "    arr_cos_sim[max_col_index][max_row_index] = -np.inf\n",
    "    v.append((max_row_index, max_col_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(48, 81),\n",
       " (6, 48),\n",
       " (5, 80),\n",
       " (42, 68),\n",
       " (33, 61),\n",
       " (7, 57),\n",
       " (74, 80),\n",
       " (3, 46),\n",
       " (0, 67),\n",
       " (18, 44)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
