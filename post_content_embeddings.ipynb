{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /usr/local/python/3.10.13/lib/python3.10/site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/codespace/.local/lib/python3.10/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /home/codespace/.local/lib/python3.10/site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from gensim) (7.0.3)\n",
      "Requirement already satisfied: wrapt in /usr/local/python/3.10.13/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "%pip install gensim\n",
    "import gensim.downloader\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_event = 'wildfire'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'subgraphs_data/{chosen_event}_subgraph.graphml'\n",
    "g = nx.read_graphml(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to try to obtain a dictionnary containing the users id and all of their posts in the network as a dictionnary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us first get access to the users of the chosen event\n",
    "users = []\n",
    "for node, data in g.nodes(data=True):\n",
    "    for key, value in data.items():\n",
    "        if key == 'labels':\n",
    "            if value == ':User':\n",
    "                users.append({node : data})\n",
    "\n",
    "# now, let us get the tweets related to the chosen event\n",
    "tweets = []\n",
    "for node, data in g.nodes(data=True):\n",
    "    for key, value in data.items():\n",
    "        if key == 'labels':\n",
    "            if value == ':Tweet':\n",
    "                tweets.append({node : data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select first a sample of 100 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "users\n",
    "users_sample = random.sample(users, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a list containing dictionnaries with the user_node_id and every tweet made by this user\n",
    "users_posts = []\n",
    "\n",
    "for u in users_sample:\n",
    "    user_node_id = [key for key, _ in u.items()][0]\n",
    "    tweets_by_user = []\n",
    "    \n",
    "    for t in tweets:\n",
    "        tweet_node_id = [key for key, _ in t.items()][0]\n",
    "        text_tweet = [value for _, value in t.items()][0]['text']\n",
    "\n",
    "        if tweet_node_id in g[user_node_id]:\n",
    "            tweets_by_user.append(text_tweet)\n",
    "\n",
    "    users_posts.append({'user':user_node_id,\n",
    "                        'tweets':tweets_by_user})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "w2v = gensim.downloader.load('glove-twitter-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_embedding(sentence):\n",
    "    tokens = sentence.split()\n",
    "    embeddings = [w2v[token] for token in tokens if token in w2v]\n",
    "    avg_embedding = np.mean(embeddings, axis=0)\n",
    "    return avg_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The @Alberta_UCP didn?t cause the fires in #Alberta but repealing the carbon tax, kneeling to/expanding the oil industry &amp; willfully ignoring and/or denying #climatechange will destroy our environment now &amp; for future generations. Shameful. That?s your ??? #abpoli #abfire #UCP']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_posts[1]['tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in users_posts:\n",
    "    tweets = i['tweets']\n",
    "    embedded_tweets = []\n",
    "    for j in i['tweets']:\n",
    "        emb_tweet = sentence_embedding(j)\n",
    "        embedded_tweets.append(emb_tweet)\n",
    "    i['embedded_tweets'] = embedded_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, let us compute the user-user similarities with a cosine similarity measure\n",
    "cos_sim = [[0 for _ in range(100)] for _ in range(100)]\n",
    "\n",
    "for i in range(len(users_posts)):\n",
    "    for j in range(len(users_posts)):\n",
    "        if i == j:\n",
    "            cos_sim[i][j] = 1\n",
    "        else:\n",
    "            emb_i = users_posts[i]['embedded_tweets']\n",
    "            emb_j = users_posts[j]['embedded_tweets']\n",
    "            cos_sim[i][j] = cosine_similarity(emb_i, emb_j)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(cos_sim)\n",
    "max_index = np.argmax(cos_sim)\n",
    "max_row_index, max_col_index = np.unravel_index(max_index, np.array(cos_sim).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_row_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_col_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
